{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7afe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/yg5d6/.conda/envs/tsai/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/iris/yg5d6/.conda/envs/tsai/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualization_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b55400af01af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvisualization_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'visualization_functions'"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tsai.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from visualization_functions import *\n",
    "from fastai.layers import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from tsai.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from visualization_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d215ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os             : Linux-4.15.0-191-generic-x86_64-with-debian-buster-sid\n",
      "python         : 3.7.12\n",
      "tsai           : 0.3.1\n",
      "fastai         : 2.6.3\n",
      "fastcore       : 1.4.3\n",
      "torch          : 1.11.0+cu102\n",
      "device         : 1 gpu (['NVIDIA GeForce RTX 2060'])\n",
      "cpu cores      : 12\n",
      "RAM            : 62.85 GB\n",
      "GPU memory     : [5.79] GB\n"
     ]
    }
   ],
   "source": [
    "computer_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fe3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FeatureMLP, self).__init__()\n",
    "        self.flatten = Reshape(-1)\n",
    "        self.mlp = nn.ModuleList()\n",
    "        self.mlp.append(LinBnDrop(48,50,bn=True, p=0.1, act=get_act_fn(nn.ReLU(inplace=True)), lin_first=False))\n",
    "        self.mlp.append(LinBnDrop(50,50,bn=True, p=0.2, act=get_act_fn(nn.ReLU(inplace=True)), lin_first=False))\n",
    "        self.mlp.append(LinBnDrop(50,50,bn=True, p=0.2, act=get_act_fn(nn.ReLU(inplace=True)), lin_first=False))\n",
    "        self.head = nn.Sequential(LinBnDrop(50,2, bn=False, p=0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        for mlp in self.mlp: x = mlp(x)\n",
    "        return self.head(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd928468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTrainTestFeatures(FEAT, LABEL, sub_test):\n",
    "    num_signal = np.shape(FEAT[sub_test,0])[0]    \n",
    "    X_Temp     = FEAT[sub_test,0]\n",
    "    Y_Temp     = LABEL[sub_test,0].flatten()\n",
    "\n",
    "    num_leftout = round(leftout*num_signal)\n",
    "    index_leftout = np.random.choice(range(num_signal), size=num_leftout, replace=False)\n",
    "    print(\"Left-out Test samples: \", index_leftout.size)\n",
    "\n",
    "    X_Test = X_Temp[index_leftout,:]\n",
    "    Y_Test = Y_Temp[index_leftout]\n",
    "\n",
    "    index_include = np.arange(num_signal)\n",
    "    index_include = np.delete(index_include, index_leftout)\n",
    "    print(\"Included Training samples: \", index_include.size)\n",
    "    \n",
    "    X_include = X_Temp[index_include,:]\n",
    "    Y_include = Y_Temp[index_include]\n",
    "\n",
    "    # ===== Load Traing Signals =====\n",
    "    X_Train = np.zeros((0,feature_dimension))\n",
    "    Y_Train = np.zeros(0)    \n",
    "    for sub_train in range(40):\n",
    "        if sub_train != sub_test:\n",
    "            x_s = FEAT_N[sub_train,0]\n",
    "            y_s = LABEL[sub_train,0].flatten()\n",
    "            # ===== CAN BE CONVERTED INTO A FUNCTION =====\n",
    "            X_Train = np.concatenate((X_Train, x_s), axis=0)\n",
    "            Y_Train = np.concatenate((Y_Train, y_s), axis=0)\n",
    "\n",
    "    X_Train = np.concatenate((X_Train, X_include), axis=0)\n",
    "    Y_Train = np.concatenate((Y_Train, Y_include), axis=0)        \n",
    "\n",
    "    print('# of Healthy Samples: %d'%(np.sum(Y_Train == -1)))\n",
    "    print('# of Fatigued Samples: %d'%(np.sum(Y_Train == 1)))   \n",
    "    \n",
    "    return X_Train, Y_Train, X_Test, Y_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b426e4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b34dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_ALL = sio.loadmat(\"subjects_88_v2.mat\")\n",
    "\n",
    "DATA_ALL = sio.loadmat(\"subjects_40_v6.mat\")\n",
    "VFI_LIST = sio.loadmat(\"Notes/VFI_new_matched.mat\")\n",
    "\n",
    "VFI_1       = np.ravel(VFI_LIST['VFI1'])\n",
    "VFI_2       = np.ravel(VFI_LIST['VFI2'])\n",
    "SIG         = DATA_ALL['DATA']              # raw sEMG signals\n",
    "FEAT        = DATA_ALL['FEAT']              # Orignally calculated features\n",
    "FEAT_N      = DATA_ALL['FEAT_N']            # Normalized features\n",
    "LABEL       = DATA_ALL['LABEL']             # Labels\n",
    "SUBJECT_ID  = DATA_ALL['SUBJECT_ID']        # Sujbect ID\n",
    "LABEL_VOWEL = DATA_ALL['LABEL_VOWEL']\n",
    "VFI         = DATA_ALL['SUBJECT_VFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735fe7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wand_config = 0\n",
    "leftout = 1\n",
    "# window_length = 4000\n",
    "feature_dimension = 48\n",
    "training_acc = np.zeros(40)\n",
    "testing_acc  = np.zeros(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74a0836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data and labels:\n",
      "(6472, 48) (6472,)\n",
      "# of Healthy  Samples: 3202\n",
      "# of Fatigued Samples: 3270\n"
     ]
    }
   ],
   "source": [
    "# X_All = np.zeros((0,4,window_length))\n",
    "X_All = np.zeros((0,feature_dimension))\n",
    "\n",
    "Y_All = np.zeros(0)    \n",
    "for sub_train in range(40):\n",
    "    \n",
    "    x_s = FEAT_N[sub_train,0]\n",
    "    y_s = LABEL[sub_train,0].flatten()\n",
    "\n",
    "    X_All = np.concatenate((X_All, x_s), axis=0)\n",
    "    Y_All = np.concatenate((Y_All, y_s), axis=0)\n",
    "\n",
    "print('Total data and labels:')                \n",
    "print(X_All.shape, Y_All.shape)\n",
    "print('# of Healthy  Samples: %d'%(np.sum(Y_All == -1)))\n",
    "print('# of Fatigued Samples: %d'%(np.sum(Y_All == 1)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921313e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_index = [0,1,2,3,4,20,21,22,23,24]\n",
    "for sub_test in sub_index:\n",
    "# for sub_test in range(40):\n",
    "    sub_txt = \"R%03d\"%(int(SUBJECT_ID[sub_test][0][0]))\n",
    "    print('Test Subject %s:'%(sub_txt))\n",
    "    print('VFI-1:', (VFI[sub_test][0][0]))\n",
    "    if int(VFI[sub_test][0][0]) > 10:\n",
    "        sub_group = 'Fatigued'\n",
    "    else:\n",
    "        sub_group = 'Healthy'\n",
    "\n",
    "    if wand_config == 1:\n",
    "        run = wandb.init(project=\"sEMG Leave-One-Out Classification 40 100 Feature Base TSAI\", \n",
    "                         group=sub_group,\n",
    "                         reinit=True, \n",
    "                         name=sub_txt)\n",
    "\n",
    "    #  Load training/testing features    \n",
    "    X_Train, Y_Train, X_Test, Y_Test = LoadTrainTestFeatures(FEAT_N, LABEL, sub_test)\n",
    "\n",
    "    #  Data initialization for fastai/pytorch\n",
    "    splits = get_splits(Y_Train, valid_size=.1, stratify=True, random_state=23, shuffle=True, show_plot=False)\n",
    "    tfms  = [None, [Categorize()]]\n",
    "    dsets = TSDatasets(X_Train, Y_Train, tfms=tfms, splits=splits)\n",
    "    \n",
    "    dls = TSDataLoaders.from_dsets(dsets.train, \n",
    "                                   dsets.valid, \n",
    "                                   shuffle_train=True,\n",
    "                                   bs=32,\n",
    "                                   num_workers=0)    \n",
    "\n",
    "    # dls.show_batch()\n",
    "\n",
    "    #  Model definitions \n",
    "    model = FeatureMLP()\n",
    "    \n",
    "    if wand_config == 1:\n",
    "        learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy, cbs=WandbCallback())\n",
    "    else:\n",
    "        learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "\n",
    "    # Training\n",
    "    with learn.no_logging():\n",
    "#         lr = learn.lr_find(stop_div=False, num_it=200)\n",
    "#         learn.fit_one_cycle(50, lr_max=0.001)\n",
    "        learn.fit(50, lr=0.001)\n",
    "    \n",
    "\n",
    "    # learn.recorder.plot_metrics()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    inp, train_probas, _, train_preds = learn.get_X_preds(X_Train.reshape((-1,1,48)), \n",
    "                                                          with_input=True, \n",
    "                                                          with_decoded=True)\n",
    "    preds = np.fromstring(train_preds[1:-1], sep=',')\n",
    "    training_acc[sub_test] = skm.accuracy_score(Y_Train, preds)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Validation accuracy:%10.6f'%(learn.validate()[1]))\n",
    "    \n",
    "    # the prediction returned by the function for some reason was in string so needed to be converted.\n",
    "    inp, test_probas , _, test_preds  = learn.get_X_preds(X_Test.reshape((-1,1,48)), \n",
    "                                                          with_input=True, \n",
    "                                                          with_decoded=True)\n",
    "    preds = np.fromstring(test_preds[1:-1], sep=',')\n",
    "    testing_acc[sub_test] = skm.accuracy_score(Y_Test, preds) \n",
    "    print(f'Testing accuracy:{skm.accuracy_score(Y_Test, preds):10.6f}\\n')\n",
    "\n",
    "    if wand_config == 1:\n",
    "        wandb.log({\"VFI-1\": int(VFI[sub_test][0][0]),\n",
    "                   \"Validation Accuracy\": learn.validate()[1],\n",
    "                   \"Testing Accuracy\": skm.accuracy_score(Y_Test, preds)})\n",
    "        run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "inp, train_probas, _, train_preds = learn.get_X_preds(X_Train.reshape((-1,1,48)), \n",
    "                                                      with_input=True, \n",
    "                                                      with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "learn.predict(X_Train.reshape((-1,1,48)), with_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test.reshape((165,1,48)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, test_probas, _, test_preds = learn.get_X_preds(X_Test.reshape((165,1,48)), with_input=True, with_decoded=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dsets.train[5001][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6cde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets.train[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, test_probas , _, test_preds  = learn.get_X_preds(X_Test.reshape((-1,1,48)), \n",
    "                                                      with_input=True, \n",
    "                                                      with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e75abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4a984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
