{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, copy, torch, argparse\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sEMG_transformer_cVAE_loo import load_raw_signals, sEMGSignalDataset, sEMGtransformerVAE, count_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"sEMG transformer training configurations\")\n",
    "# experiment config\n",
    "parser.add_argument('--sub_idx', type=int, default=0, help=\"subject index\")\n",
    "# training config\n",
    "parser.add_argument('--seed', type=int, default=0, help=\"random seed\")\n",
    "parser.add_argument('--epochs', type=int, default=1, help=\"number of epochs\")\n",
    "parser.add_argument('--bsz', type=int, default=64, help=\"batch size\")\n",
    "# optimizer config\n",
    "parser.add_argument('--lr', type=float, default=0.001, help=\"learning rate\")\n",
    "parser.add_argument('--wd', type=float, default=0.001, help=\"weight decay\")\n",
    "parser.add_argument('--step_size', type=int, default=500, help=\"lr scheduler step size\")\n",
    "parser.add_argument('--gamma', type=float, default=0.8, help=\"lr scheduler gamma\")\n",
    "# model config\n",
    "parser.add_argument('--psz', type=int, default=64, help=\"signal patch size\")\n",
    "parser.add_argument('--d_model', type=int, default=256, help=\"transformer embedding dim\")\n",
    "parser.add_argument('--nhead', type=int, default=8, help=\"transformer number of attention heads\")\n",
    "parser.add_argument('--dim_feedforward', type=int, default=1024, help=\"transformer feed-forward dim\")\n",
    "parser.add_argument('--num_layers', type=int, default=3, help=\"number of transformer encoder layers\")\n",
    "parser.add_argument('--dropout', type=float, default=0.3, help=\"dropout rate\")\n",
    "\n",
    "sys.argv = ['f']\n",
    "config = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f793845ce50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals, labels, vfi_1, sub_id, sub_skinfold = load_raw_signals(\"../data/subjects_40_v6.mat\")\n",
    "np.random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject R44\n"
     ]
    }
   ],
   "source": [
    "sub_test = config.sub_idx\n",
    "print(f\"Subject R{sub_id[config.sub_idx][0][0][0]}\")\n",
    "\n",
    "X, Y, C = [], [], []\n",
    "for i in range(40):\n",
    "  # stack all inputs into [N,C,L] format\n",
    "  x = np.stack(signals[i], axis=1)\n",
    "\n",
    "  # one-hot encode the binary labels\n",
    "  N = labels[i][0].shape[0]\n",
    "  mapped_indices = (labels[i][0] == 1).astype(int)\n",
    "  y_onehot = np.zeros((N, 2))\n",
    "  y_onehot[np.arange(N), mapped_indices.flatten()] = 1\n",
    "\n",
    "  X.append(x)\n",
    "  Y.append(y_onehot)\n",
    "  C.append(sub_skinfold[i][0].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (6472, 4, 4000)\n",
      "X_train (5676, 4, 4000)\n",
      "X_valid (631, 4, 4000)\n",
      "X_test (165, 4, 4000)\n"
     ]
    }
   ],
   "source": [
    "# normalize the signals channel-wise\n",
    "X_means = np.mean(np.concatenate(X, axis=0), axis=(0,2))\n",
    "X_stds = np.std(np.concatenate(X, axis=0), axis=(0,2))\n",
    "for i in range(40):\n",
    "  X[i] = (X[i] - X_means[np.newaxis,:,np.newaxis]) / X_stds[np.newaxis,:,np.newaxis]\n",
    "print(f\"X {np.concatenate(X, axis=0).shape}\")\n",
    "\n",
    "# leave-one-out split\n",
    "X_test, Y_test, C_test = X[sub_test], Y[sub_test], C[sub_test]\n",
    "X, Y, C = X[:sub_test] + X[sub_test+1:], Y[:sub_test] + Y[sub_test+1:], C[:sub_test] + C[sub_test+1:]\n",
    "X, Y, C = np.concatenate(X, axis=0), np.concatenate(Y, axis=0), np.concatenate(C, axis=0)\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "split_idx = int(num_samples*0.9)\n",
    "train_idx, valid_idx = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "Y_train, Y_valid = Y[train_idx], Y[valid_idx]\n",
    "C_train, C_valid = C[train_idx], C[valid_idx]\n",
    "print(f\"X_train {X_train.shape}\")\n",
    "print(f\"X_valid {X_valid.shape}\")\n",
    "print(f\"X_test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307,)\n",
      "15.85\n",
      "3.35\n"
     ]
    }
   ],
   "source": [
    "print(C.shape)\n",
    "print(C.max())\n",
    "print(C.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = sEMGSignalDataset(X_train, Y_train)\n",
    "dataset_valid = sEMGSignalDataset(X_valid, Y_valid)\n",
    "dataset_test  = sEMGSignalDataset(X_test, Y_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=config.bsz, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=config.bsz, shuffle=False)\n",
    "dataloader_test  = DataLoader(dataset_test,  batch_size=config.bsz, shuffle=False)\n",
    "\n",
    "model = sEMGtransformerVAE(patch_size=config.psz, d_model=config.d_model, nhead=config.nhead, dim_feedforward=config.dim_feedforward,\n",
    "                           dropout=config.dropout, num_layers=config.num_layers)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_valid_best = 0\n",
    "accuracy_test_best = 0\n",
    "model_best = None\n",
    "for epoch in tqdm(range(500), desc=\"Training\"):\n",
    "  loss_train = 0\n",
    "  correct_train = 0\n",
    "  model.train()\n",
    "  for batch, (inputs, targets) in enumerate(dataloader_train):\n",
    "    inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
    "\n",
    "    # make sure inputs are divisiable by the patch_size\n",
    "    # convert from raw signals to signal patches\n",
    "    inputs = inputs[:, :, :(inputs.shape[2]//config.psz)*config.psz]\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "      outputs, mu, logvar = model(inputs)\n",
    "      #print(f\"mu {mu.shape}\")\n",
    "      #print(f\"logvar {logvar.shape}\")\n",
    "      #print(f\"inputs {inputs.flatten(1).shape}\")\n",
    "      #print(f\"outputs {outputs.flatten(1).shape}\")\n",
    "      loss_mse = F.mse_loss(inputs.flatten(1), outputs.flatten(1), reduction='sum')\n",
    "      # print(loss_mse)\n",
    "      loss_kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "      # print(loss_kl)\n",
    "      loss = loss_mse + loss_kl\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    # correct_train += count_correct(outputs, targets)\n",
    "    loss_train += loss.item()\n",
    "\n",
    "  # loss_valid = 0\n",
    "  # correct_valid = 0\n",
    "  # model.eval()\n",
    "  # for inputs, targets in dataloader_valid:\n",
    "  #   inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
    "  #   outputs = model(inputs)\n",
    "  #   loss = criterion(outputs, targets)\n",
    "  #   correct_valid += count_correct(outputs, targets)\n",
    "  #   loss_valid += loss.item()\n",
    "\n",
    "  # if correct_valid/len(dataset_valid) > accuracy_valid_best: \n",
    "  #   accuracy_valid_best = correct_valid/len(dataset_valid)\n",
    "  #   print(f\"accuracy_valid_best: {accuracy_valid_best}\")\n",
    "  #   model_best = copy.deepcopy(model)\n",
    "  #   correct_test = 0\n",
    "  #   for inputs, targets in dataloader_test:\n",
    "  #     inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
    "  #     outputs = model(inputs)\n",
    "  #     correct_test += count_correct(outputs, targets)\n",
    "  #   accuracy_test_best = correct_test/len(dataset_test)\n",
    "  #   print(f\"accuracy_test_best: {accuracy_test_best}\")\n",
    "\n",
    "  scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train = C[train_idx]\n",
    "Y_train_cpt = np.argmax(Y_train, axis=1)\n",
    "Y_pred = []\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=config.bsz, shuffle=False)\n",
    "for inputs, targets in dataloader_train:\n",
    "  inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
    "  outputs = model_best(inputs)\n",
    "  _, predicted = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "  Y_pred.append(predicted.cpu().numpy())\n",
    "Y_pred_cpt = np.concatenate(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(Y_train_cpt, Y_pred_cpt)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlconfound.stats import partial_confound_test\n",
    "\n",
    "ret = partial_confound_test(Y_train_cpt, Y_pred_cpt, C_train, cat_y=True, cat_yhat=True, cat_c=False)\n",
    "print(ret.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, d_model, latent_dim):\n",
    "        super(TransformerVAE, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoderLayer(d_model=d_model, nhead=8)\n",
    "        self.decoder = nn.TransformerDecoderLayer(d_model=d_model, nhead=8)\n",
    "        \n",
    "        # Linear layers for mean and log-variance\n",
    "        self.fc_mu = nn.Linear(d_model, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(d_model, latent_dim)\n",
    "        \n",
    "        # Linear layer to map latent space back to d_model\n",
    "        self.fc_decode = nn.Linear(latent_dim, d_model)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def decode(self, z):\n",
    "        z = self.fc_decode(z)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Example usage\n",
    "d_model = 512\n",
    "latent_dim = 256\n",
    "model = TransformerVAE(d_model, latent_dim)\n",
    "x = torch.randn(10, 63, d_model)  # Example input tensor\n",
    "reconstructed_x, mu, logvar = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
